{
    "total_param": 8030.26944,
    "train_param": 360.710144,
    "dataset": "alpaca",
    "method": "alpha_peak",
    "layers": 8,
    "batch_size": 1,
    "lr": 2e-06,
    "eval_loss": 1.166485071182251,
    "forward_time": 31.577851287523906,
    "backward_time": 51.98393326997757,
    "weight_mem": 32389.5296,
    "optimizer_mem": 2885.681152,
    "activation_mem": 1775.012352,
    "grad_mem": 1560.9472,
    "input_mem": 0.004608,
    "total_mem": 35393.321984,
    "peak_mem": 41254.168064
}