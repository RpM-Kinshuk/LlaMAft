CUDA_VISIBLE_DEVICES=5 python llamaft.py \
    --output_dir /rscratch/tpang/kinshuk/RpMKin/llama_ft/data \
    --seed 7 \
    --data_seed 7 \
    --dataset alpaca \
    --max_eval_samples 1000 \
    --dataloader_num_workers 1 \
    --do_eval false \
    --max_steps 2 \
    --sortby lora \
    --num_layers 10 \
    --source_max_len 256 \
    --target_max_len 512 \
    --memlog \
    --eval_dataset_size 1024 \
    --eval_steps 187 \
    --lora_r 64 \
    --lora_alpha 16 \
    --per_device_train_batch_size 1