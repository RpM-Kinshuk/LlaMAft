{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rscratch/tpang/kinshuk/anaconda3/envs/kinbert/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-19 11:57:04.450316: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-19 11:57:04.450355: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-19 11:57:04.451581: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-19 11:57:04.458810: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-19 11:57:08.194497: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-2-7b-hf', token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "Randomly selected layers: ['model.layers.5.mlp.down_proj', 'model.layers.13.self_attn.q_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.14.mlp.down_proj', 'model.layers.22.mlp.down_proj', 'model.layers.15.self_attn.q_proj', 'model.layers.24.mlp.down_proj', 'model.layers.25.mlp.down_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.3.mlp.up_proj', 'model.layers.9.mlp.up_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.19.mlp.down_proj', 'model.layers.6.mlp.gate_proj', 'model.layers.22.self_attn.k_proj']\n",
      "{'torch.float32'}\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.24.mlp.down_proj\n",
      "model.layers.25.mlp.down_proj\n",
      "Train layers: 18\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_120281/1678150367.py:15: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  random_layers = random.sample(unique_prefixes, 18)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "unique_prefixes = set()\n",
    "count = 0\n",
    "for name, _ in param_optimizer:\n",
    "    # Extract the prefix by removing the last part (weight/bias)\n",
    "    prefix = \".\".join(name.split(\".\")[:-1])\n",
    "\n",
    "    # Print only if the prefix is encountered for the first time\n",
    "    if prefix not in unique_prefixes and \"norm\" not in prefix.lower():\n",
    "        count += 1\n",
    "        # print(prefix)\n",
    "        unique_prefixes.add(prefix)\n",
    "print(count)\n",
    "count = 0 \n",
    "random_layers = random.sample(unique_prefixes, 18)\n",
    "print(f\"Randomly selected layers: {random_layers}\")\n",
    "uqd = set()\n",
    "for name, param in model.named_parameters():\n",
    "   uqd.add(str(param.dtype))\n",
    "\n",
    "print(uqd)\n",
    "exit()\n",
    "for name, param in model.named_parameters():\n",
    "  if name.rsplit('.', 1)[0] in random_layers:\n",
    "    print(name.rsplit('.', 1)[0])\n",
    "    # if param.dtype in [torch.float32, torch.float64, torch.complex64, torch.complex128]:\n",
    "    param.requires_grad = True\n",
    "    count += 1\n",
    "print(f\"Train layers: {count}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kinbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
