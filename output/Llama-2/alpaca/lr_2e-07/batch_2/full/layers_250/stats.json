{
    "total_param": 6738.423808,
    "train_param": 6738.423808,
    "dataset": "alpaca",
    "method": "alpha",
    "layers": 250,
    "batch_size": 2,
    "lr": 2e-07,
    "eval_loss": 1.0344657897949219,
    "forward_time": 19.51293834845225,
    "backward_time": 25.24343682527542,
    "weight_mem": 28136.505344,
    "optimizer_mem": 53907.390464,
    "activation_mem": 2563.783168,
    "grad_mem": 26002.718208,
    "input_mem": 0.004608,
    "total_mem": 81092.923392,
    "peak_mem": 136167.497216
}