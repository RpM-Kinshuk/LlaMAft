{
    "total_param": 8030.26944,
    "train_param": 7504.662528,
    "dataset": "alpaca",
    "method": "alpha",
    "layers": 224,
    "batch_size": 1,
    "lr": 2e-07,
    "eval_loss": 1.1647461652755737,
    "forward_time": 82.32933249473572,
    "backward_time": 91.62176537911097,
    "weight_mem": 36592.222208,
    "optimizer_mem": 60037.562368,
    "activation_mem": 902.01088,
    "grad_mem": 25918.488576,
    "input_mem": 0.00256,
    "total_mem": 92529.6256,
    "peak_mem": 156987.162624
}