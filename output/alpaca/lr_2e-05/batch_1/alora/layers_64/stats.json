{
    "total_param": 8036.683776,
    "train_param": 6.414336,
    "dataset": "alpaca",
    "method": "alora",
    "layers": 64,
    "batch_size": 1,
    "lr": 2e-05,
    "eval_loss": 1.1641188859939575,
    "forward_time": 54.71430216232935,
    "backward_time": 69.30340370734532,
    "weight_mem": 32415.186944,
    "optimizer_mem": 51.314688,
    "activation_mem": 1310.278656,
    "grad_mem": 101.182464,
    "input_mem": 0.00256,
    "total_mem": 32542.029312,
    "peak_mem": 40901.668864
}