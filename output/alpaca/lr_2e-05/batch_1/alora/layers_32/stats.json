{
    "total_param": 8033.284096,
    "train_param": 3.014656,
    "dataset": "alpaca",
    "method": "alora",
    "layers": 32,
    "batch_size": 1,
    "lr": 2e-05,
    "eval_loss": 1.1679408550262451,
    "forward_time": 51.99799064795176,
    "backward_time": 69.47963432470958,
    "weight_mem": 32401.588224,
    "optimizer_mem": 24.117248,
    "activation_mem": 1103.881216,
    "grad_mem": 83.479552,
    "input_mem": 0.00256,
    "total_mem": 32497.12896,
    "peak_mem": 40469.008896
}