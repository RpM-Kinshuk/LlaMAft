2024-07-05 00:05:33;INFO;

alpaca Seed 41Batch Size 1 random fine-tuning 14 Layers
2024-07-05 00:05:33;INFO;
Total param      : 8030.26944
Train param      : 285.212672
Dataset          : alpaca
Method           : random
Layers           : 14
Batch size       : 1
Learning Rate    : 2e-06
Eval Loss        : 1.1648668050765991
Forward time     : 47.34348071813584 min
Backward time    : 70.20697462161382 min
Weight memory    : 32389.5296 MB
Optimizer memory : 2281.988096 MB
Activation memory: 1098.060893075387 MB
Gradient memory  : 1211.5392249034662 MB
Input memory     : 0.0026754829825215293 MB
Total memory     : 35856.958976 MB
Peak memory      : 42721.946624 MB


