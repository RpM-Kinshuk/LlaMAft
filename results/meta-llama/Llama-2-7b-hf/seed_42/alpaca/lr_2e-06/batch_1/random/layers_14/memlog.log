2024-06-27 18:16:39;INFO;

alpaca Seed 42Batch Size 1 random fine-tuning 14 Layers
2024-06-27 18:16:39;INFO;
Total param      : 6738.423808
Train param      : 433.061888
Dataset          : alpaca
Method           : random
Layers           : 14
Batch size       : 1
Learning Rate    : 2e-06
Eval Loss        : 1.0499897003173828
Forward time     : 25.54170178969701 min
Backward time    : 59.47281322479248 min
Weight memory    : 26953.711616 MB
Optimizer memory : 3464.495104 MB
Activation memory: 973.078153579222 MB
Gradient memory  : 1765.6005281553644 MB
Input memory     : 0.003071839300076505 MB
Total memory     : 32181.449216 MB
Peak memory      : 35949.382656 MB


