{
    "total_param": 6738.423808,
    "train_param": 404.750336,
    "dataset": "alpaca",
    "method": "block_ww",
    "layers": 2,
    "batch_size": 1,
    "lr": 2e-06,
    "eval_loss": 1.125661849975586,
    "forward_time": 14.12089478969574,
    "backward_time": 12.40695368051529,
    "weight_mem": 27087.929344,
    "optimizer_mem": 3238.002688,
    "activation_mem": 292.73344,
    "grad_mem": 1647.689728,
    "input_mem": 0.00256,
    "total_mem": 30354.622976,
    "peak_mem": 33658.940416
}