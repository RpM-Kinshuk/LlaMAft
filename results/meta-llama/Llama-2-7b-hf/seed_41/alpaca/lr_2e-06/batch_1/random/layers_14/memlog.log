2024-07-05 02:17:04;INFO;

alpaca Seed 41Batch Size 1 random fine-tuning 14 Layers
2024-07-05 02:17:04;INFO;
Total param      : 6738.423808
Train param      : 319.81568
Dataset          : alpaca
Method           : random
Layers           : 14
Batch size       : 1
Learning Rate    : 2e-06
Eval Loss        : 1.048864483833313
Forward time     : 26.16138917207718 min
Backward time    : 59.303340029716495 min
Weight memory    : 26953.711616 MB
Optimizer memory : 2558.52544 MB
Activation memory: 990.1959590861761 MB
Gradient memory  : 1312.6157224097142 MB
Input memory     : 0.003071839300076505 MB
Total memory     : 30816.477696 MB
Peak memory      : 35129.993216 MB


